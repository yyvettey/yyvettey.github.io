---
title: "Bridging the Gap Between Computational Photography and Visual Recognition"
collection: publications
permalink: /publication/CVPRW18_UG2_Challenge_Bridging_Gap_Between_Computational_Photography_and_Visual_Recognition
date: 2019-01-28
venue: 'Arxiv Preprint'
paperurl: 'https://arxiv.org/abs/1901.09482'
citation: 'Rosaura G. VidalMata et al. (2019). &quot;Bridging the Gap Between Computational Photography and Visual Recognition&quot; <i>Arxiv Preprint</i>. 1901.09482.'
excerpt: 'In this paper, we introduced the UG2 dataset as a large-scale benchmark
composed of video imagery captured under challenging conditions, and two enhancement tasks designed to test algorithmic impact on
visual quality and automatic object recognition. Furthermore, we proposed a set of metrics to evaluate the joint improvement of such
tasks as well as individual algorithmic advances, including a novel psychophysics-based evaluation regime for human assessment and
a realistic set of quantitative measures for object recognition performance. We introduced six new algorithms for image restoration or
enhancement, which were created as part of the IARPA sponsored UG2 Challenge workshop held at CVPR 2018.'

---
## Author(s)
Rosaura G. VidalMata, Sreya Banerjee, Brandon RichardWebster, Michael Albright, Pedro Davalos,
Scott McCloskey, Ben Miller, Asong Tambo, Sushobhan Ghosh, Sudarshan Nagesh, Ye Yuan, Yueyu Hu,
Junru Wu, Wenhan Yang, Xiaoshuai Zhang, Jiaying Liu, Zhangyang Wang, Hwann-Tzong Chen,
Tzu-Wei Huang, Wen-Chi Chin, Yi-Chun Li, Mahmoud Lababidi, Charles Otto, and Walter J. Scheirer

## Abstract
What is the current state-of-the-art for image restoration and enhancement applied to degraded images acquired under less
than ideal circumstances? Can the application of such algorithms as a pre-processing step to improve image interpretability for manual
analysis or automatic visual recognition to classify scene content? While there have been important advances in the area of
computational photography to restore or enhance the visual quality of an image, the capabilities of such techniques have not always
translated in a useful way to visual recognition tasks. Consequently, there is a pressing need for the development of algorithms that are
designed for the joint problem of improving visual appearance and recognition, which will be an enabling factor for the deployment of
visual recognition tools in many real-world scenarios. To address this, we introduce the UG2 dataset as a large-scale benchmark
composed of video imagery captured under challenging conditions, and two enhancement tasks designed to test algorithmic impact on
visual quality and automatic object recognition. Furthermore, we propose a set of metrics to evaluate the joint improvement of such
tasks as well as individual algorithmic advances, including a novel psychophysics-based evaluation regime for human assessment and
a realistic set of quantitative measures for object recognition performance. We introduce six new algorithms for image restoration or
enhancement, which were created as part of the IARPA sponsored UG2 Challenge workshop held at CVPR 2018. Under the proposed
evaluation regime, we present an in-depth analysis of these algorithms and a host of deep learning-based and classic baseline
approaches. From the observed results, it is evident that we are in the early days of building a bridge between computational
photography and visual recognition, leaving many opportunities for innovation in this area.

[Download paper here](https://arxiv.org/pdf/1901.09482.pdf)

## Citation
@article{vidalmata2019bridging,
  title={Bridging the Gap Between Computational Photography and Visual Recognition},
  author={VidalMata, Rosaura G and Banerjee, Sreya and others},
  journal={arXiv preprint arXiv:1901.09482},
  year={2019}
}